{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Thư viện"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "from docx import Document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Thực thi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Hàm đếm từ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hàm đếm số tokens đơn giản dựa trên khoảng trắng\n",
    "def count_tokens_simple(text):\n",
    "    return len(text.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Hàm trích xuất các từ khóa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hàm trích xuất từ khóa từ văn bản, loại bỏ dấu câu ngoại trừ \"/\" và \"-\"\n",
    "def extract_keywords(text):\n",
    "    text = re.sub(r'[^\\w\\s/-]', '', text)\n",
    "    words = text.split()\n",
    "    unique_words = list(dict.fromkeys(words))  # Loại bỏ từ trùng lặp\n",
    "    return unique_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hàm xử lý các từ khóa: chuyển về chữ thường, giữ nguyên số La Mã và từ khóa có \"/\" hoặc \"-\"\n",
    "def process_keywords(keywords):\n",
    "    result = []\n",
    "    roman_numeral_pattern = re.compile(r\"^(?=[MDCLXVI])M{0,4}(CM|CD|D?C{0,3})(XC|XL|L?X{0,3})(IX|IV|V?I{0,3})$\")\n",
    "    \n",
    "    for word in keywords:\n",
    "        if roman_numeral_pattern.match(word) or any(c in word for c in \"/-\"):\n",
    "            result.append(word)\n",
    "        else:\n",
    "            result.append(word.lower())  # Chuyển các từ còn lại thành chữ thường\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3. Hàm xử lý từ khóa cho các key có giá trị không null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_value_to_keywords(value):\n",
    "    if value is None or value.strip() == \"\":\n",
    "        return None\n",
    "    keywords = extract_keywords(value)\n",
    "    return process_keywords(keywords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4. Hàm xử lý tên file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_file_name(file_name):\n",
    "    parts = file_name.replace('.docx', '').split('_')\n",
    "\n",
    "    if len(parts) != 8:\n",
    "        return None  # Nếu file không hợp lệ\n",
    "    \n",
    "    stt = parts[0]\n",
    "    loai_van_ban = parts[1]\n",
    "    noi_ban_hanh = parts[2]\n",
    "    so_hieu = parts[3].replace(\"-\", \"/\")\n",
    "    linhvuc_nganh = parts[4]\n",
    "    ngay_ban_hanh = parts[5].replace(\"-\", \"/\")\n",
    "    ngay_hieu_luc = parts[6] if parts[6] == \"Đã biết\" else parts[6].replace(\"-\", \"/\")\n",
    "    chu_de = parts[7]\n",
    "    \n",
    "    # Trích xuất và xử lý từ khóa từ file name\n",
    "    metadata_keywords = extract_keywords(f\"{loai_van_ban} {noi_ban_hanh} {so_hieu} {linhvuc_nganh} {ngay_ban_hanh} {ngay_hieu_luc} {chu_de}\")\n",
    "    metadata_keywords = process_keywords(metadata_keywords)\n",
    "\n",
    "    return {\n",
    "        \"stt\": stt,\n",
    "        \"loai_van_ban\": loai_van_ban,\n",
    "        \"loai_van_ban_Keywords\": process_value_to_keywords(loai_van_ban),\n",
    "        \"noi_ban_hanh\": noi_ban_hanh,\n",
    "        \"noi_ban_hanh_Keywords\": process_value_to_keywords(noi_ban_hanh),\n",
    "        \"so_hieu\": so_hieu,\n",
    "        \"linhvuc_nganh\": linhvuc_nganh,\n",
    "        \"linhvuc_nganh_Keywords\": process_value_to_keywords(linhvuc_nganh),\n",
    "        \"ngay_ban_hanh\": ngay_ban_hanh,\n",
    "        \"ngay_hieu_luc\": ngay_hieu_luc,\n",
    "        \"chu_de\": chu_de,\n",
    "        \"chu_de_Keywords\": process_value_to_keywords(chu_de),\n",
    "        \"key_words\": metadata_keywords  # Trả về từ khóa đã xử lý\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5. Hàm đọc và xử lý nội dung của file .docx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_docx(file_path, file_metadata, max_tokens=None):  \n",
    "    document = Document(file_path)\n",
    "\n",
    "    current_chapter = None\n",
    "    current_section = None\n",
    "    current_mini_section = None\n",
    "    data = []\n",
    "    \n",
    "    for i in range(len(document.paragraphs)):\n",
    "        paragraph_text = document.paragraphs[i].text.strip()\n",
    "\n",
    "        # Bắt đầu một Chương mới\n",
    "        if paragraph_text.startswith(\"Chương\"):\n",
    "            current_chapter = paragraph_text\n",
    "            current_section = None\n",
    "            current_mini_section = None\n",
    "            if i + 1 < len(document.paragraphs):\n",
    "                next_paragraph = document.paragraphs[i + 1].text.strip()\n",
    "                if not next_paragraph.startswith((\"Mục\", \"Tiểu mục\", \"Điều\")):\n",
    "                    current_chapter += f\": {next_paragraph}\"\n",
    "            continue\n",
    "\n",
    "        # Bắt đầu một Mục mới\n",
    "        if paragraph_text.startswith(\"Mục\"):\n",
    "            current_section = paragraph_text\n",
    "            current_mini_section = None\n",
    "            continue\n",
    "\n",
    "        # Bắt đầu một Tiểu mục mới\n",
    "        if paragraph_text.startswith(\"Tiểu mục\"):\n",
    "            current_mini_section = paragraph_text\n",
    "            continue\n",
    "\n",
    "        # Bắt đầu một Điều mới\n",
    "        if paragraph_text.startswith(\"Điều\"):\n",
    "            article = paragraph_text\n",
    "            content = []\n",
    "            article_sections = []\n",
    "\n",
    "            # Tạo mảng A chứa các đoạn văn trong Điều\n",
    "            A = []\n",
    "            for j in range(i + 1, len(document.paragraphs)):\n",
    "                next_paragraph = document.paragraphs[j].text.strip()\n",
    "\n",
    "                # Nếu gặp Chương, Mục, Tiểu mục, Điều mới thì dừng lại\n",
    "                if next_paragraph.startswith((\"Chương\", \"Mục\", \"Tiểu mục\", \"Điều\")):\n",
    "                    break\n",
    "                A.append(next_paragraph)\n",
    "            \n",
    "            # Tạo mảng B chứa các đoạn văn bắt đầu bằng số (Khoản)\n",
    "            B = [para for para in A if re.match(r'^\\d+\\.', para)]\n",
    "\n",
    "            # Đếm số Khoản (số đoạn bắt đầu bằng số)\n",
    "            num_of_clauses = len(B)\n",
    "\n",
    "            # Duyệt qua từng Khoản (nếu có)\n",
    "            if num_of_clauses > 0:\n",
    "                for clause_index in range(1, num_of_clauses + 1):\n",
    "                    section_content = []\n",
    "                    found_clause = False\n",
    "\n",
    "                    # Duyệt qua mảng A để trích xuất nội dung của từng Khoản\n",
    "                    for para in A:\n",
    "                        # Nếu gặp Khoản mới (đoạn bắt đầu bằng số)\n",
    "                        if re.match(rf'^{clause_index}\\.', para):\n",
    "                            found_clause = True\n",
    "                            section_content.append(para)  # Lưu lại đoạn văn của Khoản\n",
    "                        elif found_clause and re.match(r'^\\d+\\.', para):\n",
    "                            # Nếu gặp đoạn văn bắt đầu bằng số tiếp theo (Khoản mới) thì dừng lại\n",
    "                            break\n",
    "                        elif found_clause:\n",
    "                            section_content.append(para)  # Lưu nội dung các đoạn văn trong Khoản\n",
    "\n",
    "                    # Lưu dữ liệu của Khoản\n",
    "                    section_text = \"\\n\".join(section_content).strip()\n",
    "\n",
    "                    # Tạo từ khóa bao gồm các trường \"Chapter\", \"Section\", \"Mini-Section\", và \"Article-Section\"\n",
    "                    structural_info = f\"{current_chapter} {current_section or ''} {current_mini_section or ''} {f'Khoản {clause_index}'}\"\n",
    "                    content_key_words = process_keywords(extract_keywords(f\"{article}\\n{section_text} {structural_info}\"))\n",
    "                    all_key_words = list(dict.fromkeys(file_metadata[\"key_words\"] + content_key_words))\n",
    "\n",
    "                    # Xử lý từ khóa có ký tự \"/\"\n",
    "                    for kw in all_key_words[:]:\n",
    "                        if \"/\" in kw:\n",
    "                            new_kw = kw.replace(\"/\", \"-\")\n",
    "                            if new_kw not in all_key_words:\n",
    "                                all_key_words.append(new_kw)\n",
    "\n",
    "                    noiDung_Khoan = f\"Khoản {clause_index}\"\n",
    "\n",
    "                    # Tạo trường \"combine_Article_Content\"\n",
    "                    combine_article_content = f\"{article}\\n{section_text}\"\n",
    "                    combine_article_content_keywords = process_keywords(extract_keywords(combine_article_content))\n",
    "\n",
    "                    # Lưu dữ liệu Khoản vào mảng data\n",
    "                    data.append({\n",
    "                        \"Chapter\": current_chapter,\n",
    "                        \"Chapter_Keywords\": process_value_to_keywords(current_chapter),\n",
    "                        \"Section\": current_section if current_section else None,\n",
    "                        \"Section_Keywords\": process_value_to_keywords(current_section),\n",
    "                        \"Mini-Section\": current_mini_section if current_mini_section else None,\n",
    "                        \"Mini-Section_Keywords\": process_value_to_keywords(current_mini_section),\n",
    "                        \"Article\": article,\n",
    "                        \"Article_Keywords\": process_value_to_keywords(article),\n",
    "                        \"Content\": section_text,  # Nội dung của Khoản\n",
    "                        \"Content_Keywords\": process_value_to_keywords(section_text),\n",
    "                        \"Article-Section\": noiDung_Khoan,  # Loại bỏ dấu chấm\n",
    "                        \"Article-Section_Keywords\": process_value_to_keywords(noiDung_Khoan),\n",
    "                        \"combine_Article_Content\": combine_article_content,\n",
    "                        \"combine_Article_Content_Keywords\": combine_article_content_keywords,  # Từ khóa cho combine_Article_Content\n",
    "                        \"key_words\": all_key_words\n",
    "                    })\n",
    "            else:\n",
    "                # Trường hợp không có Khoản\n",
    "                content_text = \"\\n\".join(A).strip()\n",
    "\n",
    "                # Tạo từ khóa bao gồm các trường \"Chapter\", \"Section\", \"Mini-Section\", và \"Article-Section\"\n",
    "                structural_info = f\"{current_chapter} {current_section or ''} {current_mini_section or ''}\"\n",
    "                content_key_words = process_keywords(extract_keywords(f\"{article}\\n{content_text} {structural_info}\"))\n",
    "                all_key_words = list(dict.fromkeys(file_metadata[\"key_words\"] + content_key_words))\n",
    "\n",
    "                # Xử lý từ khóa có ký tự \"/\"\n",
    "                for kw in all_key_words[:]:\n",
    "                    if \"/\" in kw:\n",
    "                        new_kw = kw.replace(\"/\", \"-\")\n",
    "                        if new_kw not in all_key_words:\n",
    "                            all_key_words.append(new_kw)\n",
    "\n",
    "                # Tạo trường \"combine_Article_Content\"\n",
    "                combine_article_content = f\"{article}\\n{content_text}\"\n",
    "                combine_article_content_keywords = process_keywords(extract_keywords(combine_article_content))\n",
    "\n",
    "                # Lưu dữ liệu Điều không có Khoản\n",
    "                data.append({\n",
    "                    \"Chapter\": current_chapter,\n",
    "                    \"Chapter_Keywords\": process_value_to_keywords(current_chapter),\n",
    "                    \"Section\": current_section if current_section else None,\n",
    "                    \"Section_Keywords\": process_value_to_keywords(current_section),\n",
    "                    \"Mini-Section\": current_mini_section if current_mini_section else None,\n",
    "                    \"Mini-Section_Keywords\": process_value_to_keywords(current_mini_section),\n",
    "                    \"Article\": article,\n",
    "                    \"Article_Keywords\": process_value_to_keywords(article),\n",
    "                    \"Content\": content_text,\n",
    "                    \"Content_Keywords\": process_value_to_keywords(content_text),\n",
    "                    \"Article-Section\": None,\n",
    "                    \"Article-Section_Keywords\": None,\n",
    "                    \"combine_Article_Content\": combine_article_content,\n",
    "                    \"combine_Article_Content_Keywords\": combine_article_content_keywords,  # Từ khóa cho combine_Article_Content\n",
    "                    \"key_words\": all_key_words\n",
    "                })\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6. Hàm chính xử lý tất cả các file trong thư mục"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_folder(folder_path, output_json_path, max_tokens):\n",
    "    all_data = []\n",
    "    \n",
    "    for file_name in os.listdir(folder_path):\n",
    "        if file_name.endswith(\".docx\"):\n",
    "            file_metadata = process_file_name(file_name)\n",
    "            if file_metadata is None:\n",
    "                continue\n",
    "            \n",
    "            file_path = os.path.join(folder_path, file_name)\n",
    "            docx_data = process_docx(file_path, file_metadata, max_tokens=max_tokens)\n",
    "            \n",
    "            for entry in docx_data:\n",
    "                combined_entry = {**file_metadata, **entry}\n",
    "                all_data.append(combined_entry)\n",
    "    \n",
    "    with open(output_json_path, 'w', encoding='utf-8') as json_file:\n",
    "        json.dump(all_data, json_file, ensure_ascii=False, indent=4)\n",
    "    \n",
    "    print(f\"Dữ liệu đã được lưu vào file {output_json_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6. Thực thi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Đường dẫn tới thư mục và file đầu ra\n",
    "folder_path = r'data\\trich_dan_luat\\docx\\Luat'\n",
    "json_file_path = r'data\\trich_dan_luat\\json\\demo_Article-Section_Combined_Output_More_Keywords.json'\n",
    "max_tokens = None  # Giới hạn số token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dữ liệu đã được lưu vào file data\\trich_dan_luat\\json\\demo_Article-Section_Combined_Output_More_Keywords.json\n"
     ]
    }
   ],
   "source": [
    "# Chạy chương trình chính\n",
    "process_folder(folder_path, json_file_path, max_tokens)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
