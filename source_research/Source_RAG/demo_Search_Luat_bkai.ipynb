{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Thư viện"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Download_Python\\lib\\importlib\\__init__.py:127: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain_core.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n",
      "\n",
      "For example, replace imports like: `from langchain_core.pydantic_v1 import BaseModel`\n",
      "with: `from pydantic import BaseModel`\n",
      "or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n",
      "\n",
      "  return _bootstrap._gcd_import(name[level:], package, level)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\Download_Python\\lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from langchain_qdrant import Qdrant\n",
    "from qdrant_client.models import Filter, FieldCondition, MatchValue\n",
    "from langchain_community.embeddings import HuggingFaceBgeEmbeddings\n",
    "from apikeys_GEMINI import APIKeyManager\n",
    "\n",
    "from langchain.load import dumps, loads\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "MODEL_GEMINI = os.getenv(\"MODEL_GEMIMI\")\n",
    "if MODEL_GEMINI is None:\n",
    "    raise ValueError(\"Environment variable MODEL_GEMINI is not set\")\n",
    "elif not MODEL_GEMINI.startswith(\"models/\"):\n",
    "    MODEL_GEMINI = f\"models/{MODEL_GEMINI}\"\n",
    "\n",
    "APIS_GEMINI_LIST = os.getenv('APIS_GEMINI_LIST').split(',')\n",
    "key_manager = APIKeyManager(APIS_GEMINI_LIST)\n",
    "\n",
    "URL_QDRANT_3 = os.getenv(\"URL_QDRANT_3\")\n",
    "API_QDRANT_3 = os.getenv(\"API_QDRANT_3\")\n",
    "\n",
    "MAX_DOCS_FOR_CONTENT = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Mô hình embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Mô hình bkai cho Qdrant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDINGS_MODEL_bkai = \"bkai-foundation-models/vietnamese-bi-encoder\"\n",
    "model_kwargs = {\"device\": \"cpu\"}\n",
    "encode_kwargs = {\"normalize_embeddings\": True}\n",
    "\n",
    "embeddings_bkai = HuggingFaceBgeEmbeddings(\n",
    "    model_name=EMBEDDINGS_MODEL_bkai,\n",
    "    model_kwargs=model_kwargs,\n",
    "    encode_kwargs=encode_kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Mô hình paraphrase-multilingual-mpnet-base-v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Download_Python\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "MODEL_RERANK = 'sentence-transformers/paraphrase-multilingual-mpnet-base-v2'\n",
    "rerank_model = SentenceTransformer(MODEL_RERANK)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Kết nối đến Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Luat_bkai_Article-Section_More_Keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "exist_ASMK_Collection = Qdrant.from_existing_collection(\n",
    "    embedding = embeddings_bkai,\n",
    "    # url = URL_QDRANT_3,\n",
    "    # api_key = API_QDRANT_3,\n",
    "    # prefer_grpc=True,\n",
    "    url = \"http://localhost:6333/\",\n",
    "    collection_name = \"Luat_bkai_Article-Section_More_Keywords_Ver-combine_Article_Content\",\n",
    "\tmetadata_payload_key=\"metadata\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. Luat_bkai_Article_More_Keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "exist_AMK_Collection = Qdrant.from_existing_collection(\n",
    "    embedding = embeddings_bkai,\n",
    "    # url = URL_QDRANT_3,\n",
    "    # api_key = API_QDRANT_3,\n",
    "    # prefer_grpc=True,\n",
    "    url = \"http://localhost:6333/\",\n",
    "    collection_name = \"Luat_bkai_Article_More_Keywords\",\n",
    "\tmetadata_payload_key=\"metadata\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Hàm sinh ra Similarity Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_generator(original_query: str, key_manager) -> list[str]:\n",
    "    \"\"\"Generate queries from original query\"\"\"\n",
    "    # Câu truy vấn gốc\n",
    "    query = original_query\n",
    "    \n",
    "    # Cập nhật prompt để yêu cầu rõ ràng chỉ trả về 3 câu truy vấn và câu gốc\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", \"Bạn là một trợ lý hữu ích và có nhiệm vụ tạo ra nhiều truy vấn tìm kiếm dựa trên một truy vấn gốc.\"),\n",
    "            (\"human\", \"\"\"Tạo chính xác 3 câu truy vấn tìm kiếm liên quan đến: {original_query}. Mỗi câu truy vấn trên một dòng mới. \n",
    "            Không được trả về nhiều hơn hoặc ít hơn 3 câu truy vấn. Đảm bảo không thêm bất kỳ văn bản nào khác ngoài 3 câu truy vấn này.\"\"\"),\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    model = ChatGoogleGenerativeAI(\n",
    "        # key api google gemini, nếu test mà bị báo lỗi api core thì lấy api khác trong .env để test\n",
    "        google_api_key=key_manager.get_next_key(),\n",
    "        model=MODEL_GEMINI,\n",
    "        temperature=0.15\n",
    "    )\n",
    "    \n",
    "    query_generator_chain = (\n",
    "        prompt | model | StrOutputParser()\n",
    "    )\n",
    "    \n",
    "    # Kết quả sẽ là một chuỗi các câu truy vấn cách nhau bằng dấu xuống dòng\n",
    "    result = query_generator_chain.invoke({\"original_query\": query})\n",
    "    \n",
    "    # Tách kết quả thành danh sách các câu truy vấn\n",
    "    generated_queries = result.strip().split('\\n')\n",
    "    \n",
    "    # Đảm bảo chỉ lấy 3 câu truy vấn nếu có nhiều hơn 3 câu sinh ra\n",
    "    if len(generated_queries) > 3:\n",
    "        generated_queries = generated_queries[:len(generated_queries) - 1]\n",
    "    \n",
    "    # Kết hợp câu gốc với các câu truy vấn sinh ra\n",
    "    queries = [query] + generated_queries\n",
    "    \n",
    "    return queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Tách Keywords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1. Tách keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hàm trích xuất từ khóa từ văn bản, loại bỏ dấu câu ngoại trừ \"/\" và \"-\"\n",
    "def extract_keywords(text):\n",
    "    text = re.sub(r'[^\\w\\s/-]', '', text)  # Loại bỏ các dấu câu không mong muốn\n",
    "    words = text.split()                   # Tách các từ theo khoảng trắng\n",
    "    unique_words = list(dict.fromkeys(words))  # Loại bỏ từ trùng lặp\n",
    "    return unique_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2. Xử lý lower case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hàm xử lý các từ khóa: chuyển về chữ thường, giữ nguyên số La Mã và từ khóa có \"/\" hoặc \"-\"\n",
    "def process_keywords(keywords):\n",
    "    result = []\n",
    "    roman_numeral_pattern = re.compile(r\"^(?=[MDCLXVI])M{0,4}(CM|CD|D?C{0,3})(XC|XL|L?X{0,3})(IX|IV|V?I{0,3})$\")\n",
    "    \n",
    "    for word in keywords:\n",
    "        if roman_numeral_pattern.match(word) or any(c in word for c in \"/-\"):\n",
    "            result.append(word)\n",
    "        else:\n",
    "            result.append(word.lower())  # Chuyển các từ còn lại thành chữ thường\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Truy vấn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1. Hàm print_Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_Results_MoreKeywords(results):\n",
    "    # for doc,score in results:\n",
    "    #     print(\"Page_Content:\\n\",doc.page_content)\n",
    "    #     # print(\"Context:\\n\",doc.metadata['context'],\"\\n\")\n",
    "        # print(\"Stt:\",doc.metadata['stt'])\n",
    "        # print(\"Số hiệu:\",doc.metadata['so_hieu'])\n",
    "        # print(\"Chủ đề:\",doc.metadata['chu_de'])\n",
    "        # print(\"Chương:\",doc.metadata[\"Chapter\"])\n",
    "        # print(\"Mục:\",doc.metadata[\"Section\"])\n",
    "        # print(\"Tiểu mục:\",doc.metadata[\"Mini-Section\"])\n",
    "        # print(\"Điều:\",doc.metadata[\"Article\"])\n",
    "        # print(\"Khoản:\",doc.metadata[\"Article-Section\"])\n",
    "    #     print(\"Score:\",score,\"\\n\",\"-----------------------\")\n",
    "    for result in results:\n",
    "        doc = result[0]  # lấy phần tử đầu tiên\n",
    "        score_Qdrant = result[1]  # lấy phần tử thứ hai\n",
    "        score_Rerank = result[2]\n",
    "        print(\"Page_Content:\\n\", doc.page_content)\n",
    "        print(\"Stt:\",doc.metadata['stt'])\n",
    "        print(\"Số hiệu:\",doc.metadata['so_hieu'])\n",
    "        print(\"Chủ đề:\",doc.metadata['chu_de'])\n",
    "        print(\"Chương:\",doc.metadata[\"Chapter\"])\n",
    "        print(\"Mục:\",doc.metadata[\"Section\"])\n",
    "        print(\"Tiểu mục:\",doc.metadata[\"Mini-Section\"])\n",
    "        print(\"Điều:\",doc.metadata[\"Article\"])\n",
    "        print(\"Khoản:\",doc.metadata[\"Article-Section\"])\n",
    "        print(\"Page_Rerank:\", score_Rerank)\n",
    "        print(\"Score Qdrant:\",score_Qdrant,\"\\n\",\"-----------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2. Tạo Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_should_filter(user_keywords, metadata_fields):\n",
    "    should_conditions = []\n",
    "\n",
    "    for keyword in user_keywords:\n",
    "        for field in metadata_fields:\n",
    "            should_conditions.append(FieldCondition(\n",
    "                key=field, \n",
    "                match=MatchValue(value=keyword)\n",
    "            ))\n",
    "\n",
    "    # Trả về bộ lọc với các điều kiện `should`\n",
    "    return Filter(\n",
    "        should=should_conditions\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3. Truy vấn với Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_documents_with_should_filter(user_query, metadata_fields, top_k=5):\n",
    "    # Tách keywords từ query của user\n",
    "    user_keywords = process_keywords(extract_keywords(user_query))\n",
    "    \n",
    "    # Tạo bộ lọc `should`\n",
    "    filter_conditions = create_should_filter(user_keywords, metadata_fields)\n",
    "    \n",
    "    # Thực hiện tìm kiếm trên Qdrant với filter `should`\n",
    "    search_results = exist_ASMK_Collection.similarity_search_with_score(\n",
    "        query=user_query,\n",
    "        filter=filter_conditions,\n",
    "        k=top_k\n",
    "    )\n",
    "    \n",
    "    return search_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combined_search(user_query: str, key_manager, metadata_fields, top_k=5):\n",
    "    # Gọi hàm query_generator để sinh ra 3 truy vấn từ query gốc\n",
    "    queries = query_generator(user_query, key_manager)\n",
    "\n",
    "    print(\"4 câu queries:\\n\")\n",
    "    for q in queries:\n",
    "        print(q)\n",
    "\n",
    "    print(\"\\nCác kết quả trả về:\\n\")\n",
    "    # Lưu trữ kết quả cho từng query\n",
    "    query_results = []\n",
    "\n",
    "    # Thực hiện tìm kiếm cho mỗi query trong danh sách queries\n",
    "    for query in queries:\n",
    "        search_results = search_documents_with_should_filter(query, metadata_fields, top_k=top_k)\n",
    "        query_results.extend(search_results)  # Lưu kết quả riêng cho từng query\n",
    "\n",
    "    # Dictionary để lưu các kết quả unique, key là `doc.page_content`\n",
    "    unique_results = {}\n",
    "\n",
    "    # Duyệt qua từng kết quả\n",
    "    for doc, score in query_results:\n",
    "        # Kiểm tra nếu `doc.page_content` đã tồn tại trong unique_results\n",
    "        if doc.page_content in unique_results:\n",
    "            # Nếu tồn tại, so sánh score và giữ lại cái có score cao hơn\n",
    "            if score > unique_results[doc.page_content][1]:\n",
    "                unique_results[doc.page_content] = (doc, score)\n",
    "        else:\n",
    "            # Nếu chưa tồn tại, thêm vào unique_results\n",
    "            unique_results[doc.page_content] = (doc, score)\n",
    "\n",
    "    # Trả về danh sách kết quả duy nhất, với các giá trị từ dictionary\n",
    "    return list(unique_results.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.4. Re-rank theo trọng số Similarity và TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_scores(user_query, unique_results):\n",
    "    # Tạo danh sách các doc.page_content từ unique_results\n",
    "    documents = [doc.page_content for doc, _ in unique_results]\n",
    "    \n",
    "    # Tính cosine similarity\n",
    "    user_query_embedding = rerank_model.encode(user_query)\n",
    "    document_embeddings = rerank_model.encode(documents)\n",
    "    cosine_similarities = cosine_similarity([user_query_embedding], document_embeddings)[0]\n",
    "\n",
    "    # Tính TF-IDF\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    tfidf_matrix = vectorizer.fit_transform([user_query] + documents)\n",
    "    tfidf_scores = tfidf_matrix.toarray()[0][1:]  # Lấy chỉ số TF-IDF cho các documents\n",
    "\n",
    "    # Tính điểm tổng hợp\n",
    "    combined_scores = []\n",
    "    for cos_sim, tfidf_score in zip(cosine_similarities, tfidf_scores):\n",
    "        combined_score = 0.7 * cos_sim + 0.3 * tfidf_score\n",
    "        combined_scores.append(combined_score)\n",
    "\n",
    "    # Tạo danh sách kết quả với điểm số\n",
    "    results_with_scores = [(unique_results[i][0], unique_results[i][1], combined_scores[i]) for i in range(len(unique_results))]\n",
    "\n",
    "    # Sắp xếp kết quả theo điểm số giảm dần\n",
    "    results_with_scores.sort(key=lambda x: x[2], reverse=True)\n",
    "\n",
    "    # Lấy top 5 kết quả\n",
    "    top_results = results_with_scores[:5]\n",
    "    \n",
    "    return top_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.5. Các metadata cần filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Các metadata fields cần lọc\n",
    "metadata_fields = [\n",
    "    \"metadata.loai_van_ban_Keywords\", \n",
    "    \"metadata.noi_ban_hanh_Keywords\", \n",
    "    \"metadata.so_hieu\", \n",
    "    \"metadata.linhvuc_nganh_Keywords\", \n",
    "    \"metadata.ngay_ban_hanh\", \n",
    "    \"metadata.ngay_hieu_luc\", \n",
    "    \"metadata.chu_de_Keywords\", \n",
    "    \"metadata.Chapter_Keywords\", \n",
    "    \"metadata.Section_Keywords\",  \n",
    "    \"metadata.Mini-Section_Keywords\", \n",
    "    \"metadata.Article_Keywords\",\n",
    "    \"metadata.Article-Section_Keywords\",\n",
    "    \"metadata.Content_Keywords\",\n",
    "    \"metadata.combine_Article_Content_Keywords\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.6. Thực hiện truy vấn Khoản"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 câu queries:\n",
      "\n",
      "Thông điệp dữ liệu như file có cần công chứng hoặc chứng thực gì không để được xem là có giá trị như một văn bản, theo quy định của Luật?\n",
      "Giá trị pháp lý của dữ liệu điện tử chưa công chứng\n",
      "File dữ liệu có cần công chứng mới có hiệu lực pháp luật?\n",
      "Điều kiện để thông điệp dữ liệu được coi là văn bản theo luật định\n",
      "\n",
      "Các kết quả trả về:\n",
      "\n",
      "Page_Content:\n",
      " Điều 9. Thông điệp dữ liệu có giá trị như văn bản\n",
      "2. Trường hợp pháp luật yêu cầu văn bản phải được công chứng, chứng thực thì thông điệp dữ liệu được xem là đáp ứng yêu cầu nếu được công chứng theo quy định của pháp luật về công chứng; chứng thực theo quy định của Luật này và pháp luật về chứng thực.\n",
      "Stt: 10\n",
      "Số hiệu: 20/2023/QH15\n",
      "Chủ đề: Giao dịch điện tử\n",
      "Chương: Chương II: THÔNG ĐIỆP DỮ LIỆU\n",
      "Mục: Mục 1. GIÁ TRỊ PHÁP LÝ CỦA THÔNG ĐIỆP DỮ LIỆU\n",
      "Tiểu mục: None\n",
      "Điều: Điều 9. Thông điệp dữ liệu có giá trị như văn bản\n",
      "Khoản: Khoản 2\n",
      "Page_Rerank: 0.5817286849021911\n",
      "Score Qdrant: 0.6658102 \n",
      " -----------------------\n",
      "Page_Content:\n",
      " Điều 9. Thông điệp dữ liệu có giá trị như văn bản\n",
      "1. Trường hợp pháp luật yêu cầu thông tin phải được thể hiện bằng văn bản thì thông điệp dữ liệu được xem là đáp ứng yêu cầu nếu thông tin trong thông điệp dữ liệu đó có thể truy cập và sử dụng được để tham chiếu.\n",
      "Stt: 10\n",
      "Số hiệu: 20/2023/QH15\n",
      "Chủ đề: Giao dịch điện tử\n",
      "Chương: Chương II: THÔNG ĐIỆP DỮ LIỆU\n",
      "Mục: Mục 1. GIÁ TRỊ PHÁP LÝ CỦA THÔNG ĐIỆP DỮ LIỆU\n",
      "Tiểu mục: None\n",
      "Điều: Điều 9. Thông điệp dữ liệu có giá trị như văn bản\n",
      "Khoản: Khoản 1\n",
      "Page_Rerank: 0.5643673896789551\n",
      "Score Qdrant: 0.6306062 \n",
      " -----------------------\n",
      "Page_Content:\n",
      " Điều 11. Thông điệp dữ liệu có giá trị dùng làm chứng cứ\n",
      "1. Thông điệp dữ liệu được dùng làm chứng cứ theo quy định của Luật này và pháp luật về tố tụng.\n",
      "Stt: 10\n",
      "Số hiệu: 20/2023/QH15\n",
      "Chủ đề: Giao dịch điện tử\n",
      "Chương: Chương II: THÔNG ĐIỆP DỮ LIỆU\n",
      "Mục: Mục 1. GIÁ TRỊ PHÁP LÝ CỦA THÔNG ĐIỆP DỮ LIỆU\n",
      "Tiểu mục: None\n",
      "Điều: Điều 11. Thông điệp dữ liệu có giá trị dùng làm chứng cứ\n",
      "Khoản: Khoản 1\n",
      "Page_Rerank: 0.5574483394622802\n",
      "Score Qdrant: 0.58595246 \n",
      " -----------------------\n",
      "Page_Content:\n",
      " Điều 8. Giá trị pháp lý của thông điệp dữ liệu\n",
      "Thông tin trong thông điệp dữ liệu không bị phủ nhận giá trị pháp lý chỉ vì thông tin đó được thể hiện dưới dạng thông điệp dữ liệu.\n",
      "Stt: 10\n",
      "Số hiệu: 20/2023/QH15\n",
      "Chủ đề: Giao dịch điện tử\n",
      "Chương: Chương II: THÔNG ĐIỆP DỮ LIỆU\n",
      "Mục: Mục 1. GIÁ TRỊ PHÁP LÝ CỦA THÔNG ĐIỆP DỮ LIỆU\n",
      "Tiểu mục: None\n",
      "Điều: Điều 8. Giá trị pháp lý của thông điệp dữ liệu\n",
      "Khoản: None\n",
      "Page_Rerank: 0.49892246723175043\n",
      "Score Qdrant: 0.56762886 \n",
      " -----------------------\n",
      "Page_Content:\n",
      " Điều 7. Giá trị của tài liệu lưu trữ\n",
      "3. Tài liệu lưu trữ số có đầy đủ giá trị pháp lý như thông điệp dữ liệu theo quy định của pháp luật về giao dịch điện tử.\n",
      "Stt: 20\n",
      "Số hiệu: 33/2024/QH15\n",
      "Chủ đề: Lưu trữ\n",
      "Chương: Chương I: NHỮNG QUY ĐỊNH CHUNG\n",
      "Mục: None\n",
      "Tiểu mục: None\n",
      "Điều: Điều 7. Giá trị của tài liệu lưu trữ\n",
      "Khoản: Khoản 3\n",
      "Page_Rerank: 0.4767209410667419\n",
      "Score Qdrant: 0.43117207 \n",
      " -----------------------\n"
     ]
    }
   ],
   "source": [
    "# Ví dụ sử dụng\n",
    "user_query= \"Thông điệp dữ liệu như file có cần công chứng hoặc chứng thực gì không để được xem là có giá trị như một văn bản, theo quy định của Luật?\"\n",
    "\n",
    "search_Results = combined_search(user_query, key_manager, metadata_fields, top_k=5)\n",
    "\n",
    "re_Rank_Results = calculate_scores(user_query, search_Results)\n",
    "\n",
    "# In ra kết quả top 5 tài liệu\n",
    "print_Results_MoreKeywords(re_Rank_Results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.7. Lấy metadata để truy xuất Điều"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_unique_metadata(top_results):\n",
    "    metadata_list = []\n",
    "    metadata_dict_set = set()  # Sử dụng set để lưu trữ các metadata duy nhất\n",
    "\n",
    "    # Truy cập vào từng result trong top_results\n",
    "    for result in top_results:\n",
    "        doc = result[0]  # Lấy doc từ result\n",
    "        \n",
    "        # Tạo một dictionary chứa các thuộc tính từ metadata\n",
    "        metadata = {\n",
    "            \"stt\": doc.metadata.get('stt'),\n",
    "            \"loai_van_ban\": doc.metadata.get('loai_van_ban'),\n",
    "            \"noi_ban_hanh\": doc.metadata.get('noi_ban_hanh'),\n",
    "            \"so_hieu\": doc.metadata.get('so_hieu'),\n",
    "            \"linhvuc_nganh\": doc.metadata.get('linhvuc_nganh'),\n",
    "            \"ngay_ban_hanh\": doc.metadata.get('ngay_ban_hanh'),\n",
    "            \"ngay_hieu_luc\": doc.metadata.get('ngay_hieu_luc'),\n",
    "            \"chu_de\": doc.metadata.get('chu_de'),\n",
    "            \"Chapter\": doc.metadata.get('Chapter'),\n",
    "            \"Section\": doc.metadata.get('Section'),\n",
    "            \"Mini-Section\": doc.metadata.get('Mini-Section'),\n",
    "            \"Article\": doc.metadata.get('Article'),\n",
    "        }\n",
    "\n",
    "        # Lọc bỏ các key-value có giá trị None\n",
    "        filtered_metadata = {key: value for key, value in metadata.items() if value is not None}\n",
    "\n",
    "        # Chuyển đổi dict thành tuple để thêm vào set\n",
    "        metadata_tuple = tuple(filtered_metadata.items())\n",
    "        \n",
    "        # Kiểm tra và thêm vào set nếu chưa có\n",
    "        metadata_dict_set.add(metadata_tuple)\n",
    "\n",
    "    # Chuyển đổi lại set thành list và định dạng lại thành dict\n",
    "    for metadata_tuple in metadata_dict_set:\n",
    "        metadata_dict = dict(metadata_tuple)\n",
    "        metadata_list.append(metadata_dict)\n",
    "\n",
    "    return metadata_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'stt': '10', 'loai_van_ban': 'Luật', 'noi_ban_hanh': 'Quốc hội', 'so_hieu': '20/2023/QH15', 'linhvuc_nganh': 'Thương mại, Công nghệ thông tin, Quyền dân sự', 'ngay_ban_hanh': '22/06/2023', 'ngay_hieu_luc': '01/07/2024', 'chu_de': 'Giao dịch điện tử', 'Chapter': 'Chương II: THÔNG ĐIỆP DỮ LIỆU', 'Section': 'Mục 1. GIÁ TRỊ PHÁP LÝ CỦA THÔNG ĐIỆP DỮ LIỆU', 'Article': 'Điều 11. Thông điệp dữ liệu có giá trị dùng làm chứng cứ'}, {'stt': '10', 'loai_van_ban': 'Luật', 'noi_ban_hanh': 'Quốc hội', 'so_hieu': '20/2023/QH15', 'linhvuc_nganh': 'Thương mại, Công nghệ thông tin, Quyền dân sự', 'ngay_ban_hanh': '22/06/2023', 'ngay_hieu_luc': '01/07/2024', 'chu_de': 'Giao dịch điện tử', 'Chapter': 'Chương II: THÔNG ĐIỆP DỮ LIỆU', 'Section': 'Mục 1. GIÁ TRỊ PHÁP LÝ CỦA THÔNG ĐIỆP DỮ LIỆU', 'Article': 'Điều 8. Giá trị pháp lý của thông điệp dữ liệu'}, {'stt': '10', 'loai_van_ban': 'Luật', 'noi_ban_hanh': 'Quốc hội', 'so_hieu': '20/2023/QH15', 'linhvuc_nganh': 'Thương mại, Công nghệ thông tin, Quyền dân sự', 'ngay_ban_hanh': '22/06/2023', 'ngay_hieu_luc': '01/07/2024', 'chu_de': 'Giao dịch điện tử', 'Chapter': 'Chương II: THÔNG ĐIỆP DỮ LIỆU', 'Section': 'Mục 1. GIÁ TRỊ PHÁP LÝ CỦA THÔNG ĐIỆP DỮ LIỆU', 'Article': 'Điều 9. Thông điệp dữ liệu có giá trị như văn bản'}, {'stt': '20', 'loai_van_ban': 'Luật', 'noi_ban_hanh': 'Quốc hội', 'so_hieu': '33/2024/QH15', 'linhvuc_nganh': 'Bộ máy hành chính', 'ngay_ban_hanh': '21/06/2024', 'ngay_hieu_luc': 'Đã biết', 'chu_de': 'Lưu trữ', 'Chapter': 'Chương I: NHỮNG QUY ĐỊNH CHUNG', 'Article': 'Điều 7. Giá trị của tài liệu lưu trữ'}]\n"
     ]
    }
   ],
   "source": [
    "list_Metadata = extract_unique_metadata(re_Rank_Results)\n",
    "print(list_Metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.8. Thực hiện truy vấn Điều"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_documents_with_metadata_filter(list_Metadata, top_k=1):\n",
    "    search_results = []\n",
    "\n",
    "    # Duyệt qua từng phần tử trong list_Metadata\n",
    "    for metadata in list_Metadata:        \n",
    "        # Thực hiện tìm kiếm với query trống và bộ lọc\n",
    "        results = exist_AMK_Collection.similarity_search_with_score(\n",
    "            query=\"\",  # Query để trống\n",
    "            filter=metadata,\n",
    "            k=top_k\n",
    "        )\n",
    "        \n",
    "        # Thêm kết quả vào danh sách tìm kiếm\n",
    "        search_results.extend(results)\n",
    "\n",
    "    return search_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stt: 10 \n",
      "\n",
      "Điều và Nội dung Điều:\n",
      " Điều 11. Thông điệp dữ liệu có giá trị dùng làm chứng cứ\n",
      "1. Thông điệp dữ liệu được dùng làm chứng cứ theo quy định của Luật này và pháp luật về tố tụng.\n",
      "2. Giá trị dùng làm chứng cứ của thông điệp dữ liệu được xác định căn cứ vào độ tin cậy của cách thức khởi tạo, gửi, nhận hoặc lưu trữ thông điệp dữ liệu; cách thức bảo đảm và duy trì tính toàn vẹn của thông điệp dữ liệu; cách thức xác định người khởi tạo, gửi, nhận thông điệp dữ liệu và các yếu tố phù hợp khác. \n",
      " -----------------------\n",
      "Stt: 10 \n",
      "\n",
      "Điều và Nội dung Điều:\n",
      " Điều 8. Giá trị pháp lý của thông điệp dữ liệu\n",
      "Thông tin trong thông điệp dữ liệu không bị phủ nhận giá trị pháp lý chỉ vì thông tin đó được thể hiện dưới dạng thông điệp dữ liệu. \n",
      " -----------------------\n",
      "Stt: 10 \n",
      "\n",
      "Điều và Nội dung Điều:\n",
      " Điều 9. Thông điệp dữ liệu có giá trị như văn bản\n",
      "1. Trường hợp pháp luật yêu cầu thông tin phải được thể hiện bằng văn bản thì thông điệp dữ liệu được xem là đáp ứng yêu cầu nếu thông tin trong thông điệp dữ liệu đó có thể truy cập và sử dụng được để tham chiếu.\n",
      "2. Trường hợp pháp luật yêu cầu văn bản phải được công chứng, chứng thực thì thông điệp dữ liệu được xem là đáp ứng yêu cầu nếu được công chứng theo quy định của pháp luật về công chứng; chứng thực theo quy định của Luật này và pháp luật về chứng thực. \n",
      " -----------------------\n",
      "Stt: 20 \n",
      "\n",
      "Điều và Nội dung Điều:\n",
      " Điều 7. Giá trị của tài liệu lưu trữ\n",
      "1. Tài liệu lưu trữ là bằng chứng về hoạt động của Đảng, Nhà nước, xã hội và cơ quan, tổ chức, cá nhân, gia đình, dòng họ, cộng đồng qua các thời kỳ lịch sử của Việt Nam.\n",
      "2. Tài liệu lưu trữ có giá trị lịch sử, giá trị pháp lý và giá trị thực tiễn trong các lĩnh vực của đời sống xã hội.\n",
      "3. Tài liệu lưu trữ số có đầy đủ giá trị pháp lý như thông điệp dữ liệu theo quy định của pháp luật về giao dịch điện tử. \n",
      " -----------------------\n"
     ]
    }
   ],
   "source": [
    "article_Results = search_documents_with_metadata_filter(list_Metadata)\n",
    "\n",
    "for doc, score in article_Results:\n",
    "    print(\"Stt:\",doc.metadata['stt'],\"\\n\")\n",
    "    print(\"Điều và Nội dung Điều:\\n\",doc.metadata[\"combine_Article_Content\"],\"\\n\",\"-----------------------\")\n",
    "    # print(re)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
