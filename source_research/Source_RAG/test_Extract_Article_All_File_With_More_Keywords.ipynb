{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Thư viện"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "from docx import Document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Thực thi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Hàm đếm từ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hàm đếm số tokens đơn giản dựa trên khoảng trắng\n",
    "def count_tokens_simple(text):\n",
    "    return len(text.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Hàm trích xuất các từ khóa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hàm trích xuất từ khóa từ văn bản, loại bỏ dấu câu ngoại trừ \"/\" và \"-\"\n",
    "def extract_keywords(text):\n",
    "    text = re.sub(r'[^\\w\\s/-]', '', text)\n",
    "    words = text.split()\n",
    "    unique_words = list(dict.fromkeys(words))  # Loại bỏ từ trùng lặp\n",
    "    return unique_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hàm xử lý các từ khóa: chuyển về chữ thường, giữ nguyên số La Mã và từ khóa có \"/\" hoặc \"-\"\n",
    "def process_keywords(keywords):\n",
    "    result = []\n",
    "    roman_numeral_pattern = re.compile(r\"^(?=[MDCLXVI])M{0,4}(CM|CD|D?C{0,3})(XC|XL|L?X{0,3})(IX|IV|V?I{0,3})$\")\n",
    "    \n",
    "    for word in keywords:\n",
    "        if roman_numeral_pattern.match(word) or any(c in word for c in \"/-\"):\n",
    "            result.append(word)\n",
    "        else:\n",
    "            result.append(word.lower())  # Chuyển các từ còn lại thành chữ thường\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3. Hàm xử lý từ khóa cho các key có giá trị không null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_value_to_keywords(value):\n",
    "    if value is None or value.strip() == \"\":\n",
    "        return None\n",
    "    keywords = extract_keywords(value)\n",
    "    return process_keywords(keywords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4. Hàm xử lý tên file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_file_name(file_name):\n",
    "    parts = file_name.replace('.docx', '').split('_')\n",
    "\n",
    "    if len(parts) != 8:\n",
    "        return None  # Nếu file không hợp lệ\n",
    "    \n",
    "    stt = parts[0]\n",
    "    loai_van_ban = parts[1]\n",
    "    noi_ban_hanh = parts[2]\n",
    "    so_hieu = parts[3].replace(\"-\", \"/\")\n",
    "    linhvuc_nganh = parts[4]\n",
    "    ngay_ban_hanh = parts[5].replace(\"-\", \"/\")\n",
    "    ngay_hieu_luc = parts[6] if parts[6] == \"Đã biết\" else parts[6].replace(\"-\", \"/\")\n",
    "    chu_de = parts[7]\n",
    "    \n",
    "    # Trích xuất và xử lý từ khóa từ file name\n",
    "    metadata_keywords = extract_keywords(f\"{loai_van_ban} {noi_ban_hanh} {so_hieu} {linhvuc_nganh} {ngay_ban_hanh} {ngay_hieu_luc} {chu_de}\")\n",
    "    metadata_keywords = process_keywords(metadata_keywords)\n",
    "\n",
    "    return {\n",
    "        \"stt\": stt,\n",
    "        \"loai_van_ban\": loai_van_ban,\n",
    "        \"loai_van_ban_Keywords\": process_value_to_keywords(loai_van_ban),\n",
    "        \"noi_ban_hanh\": noi_ban_hanh,\n",
    "        \"noi_ban_hanh_Keywords\": process_value_to_keywords(noi_ban_hanh),\n",
    "        \"so_hieu\": so_hieu,\n",
    "        \"linhvuc_nganh\": linhvuc_nganh,\n",
    "        \"linhvuc_nganh_Keywords\": process_value_to_keywords(linhvuc_nganh),\n",
    "        \"ngay_ban_hanh\": ngay_ban_hanh,\n",
    "        \"ngay_hieu_luc\": ngay_hieu_luc,\n",
    "        \"chu_de\": chu_de,\n",
    "        \"chu_de_Keywords\": process_value_to_keywords(chu_de),\n",
    "        \"key_words\": metadata_keywords  # Trả về từ khóa đã xử lý\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5. Hàm đọc và xử lý nội dung của file .docx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_docx(file_path, file_metadata, max_tokens):\n",
    "    document = Document(file_path)\n",
    "    \n",
    "    current_chapter = None\n",
    "    current_section = None\n",
    "    current_mini_section = None\n",
    "    data = []\n",
    "    \n",
    "    for i in range(len(document.paragraphs)):\n",
    "        paragraph_text = document.paragraphs[i].text.strip()\n",
    "        \n",
    "        if paragraph_text.startswith(\"Chương\"):\n",
    "            current_chapter = paragraph_text\n",
    "            current_section = None\n",
    "            current_mini_section = None\n",
    "            if i + 1 < len(document.paragraphs):\n",
    "                next_paragraph = document.paragraphs[i + 1].text.strip()\n",
    "                if not next_paragraph.startswith((\"Mục\", \"Tiểu mục\", \"Điều\")):\n",
    "                    current_chapter += f\": {next_paragraph}\"\n",
    "            continue\n",
    "        \n",
    "        if paragraph_text.startswith(\"Mục\"):\n",
    "            current_section = paragraph_text\n",
    "            current_mini_section = None\n",
    "            continue\n",
    "        \n",
    "        if paragraph_text.startswith(\"Tiểu mục\"):\n",
    "            current_mini_section = paragraph_text\n",
    "            continue\n",
    "        \n",
    "        if paragraph_text.startswith(\"Điều\"):\n",
    "            article = paragraph_text\n",
    "            content = []\n",
    "            \n",
    "            for j in range(i + 1, len(document.paragraphs)):\n",
    "                next_paragraph = document.paragraphs[j].text.strip()\n",
    "                if next_paragraph.startswith((\"Chương\", \"Mục\", \"Tiểu mục\", \"Điều\")):\n",
    "                    break\n",
    "                content.append(next_paragraph)\n",
    "            \n",
    "            content_text = \"\\n\".join(content)\n",
    "            combine_article_content = f\"{article}\\n{content_text}\"\n",
    "\n",
    "            # Tạo từ khóa từ nội dung\n",
    "            content_key_words = extract_keywords(combine_article_content)\n",
    "            content_key_words = process_keywords(content_key_words)\n",
    "\n",
    "            # Tạo từ khóa tổng hợp từ file metadata và nội dung\n",
    "            combined_keywords = list(dict.fromkeys(file_metadata[\"key_words\"] + content_key_words))\n",
    "            \n",
    "            # Xử lý từ khóa có ký tự \"/\"\n",
    "            for kw in combined_keywords[:]:\n",
    "                if \"/\" in kw:\n",
    "                    new_kw = kw.replace(\"/\", \"-\")\n",
    "                    if new_kw not in combined_keywords:\n",
    "                        combined_keywords.append(new_kw)\n",
    "\n",
    "            # Tách nội dung thành từng phần dựa trên số thứ tự (1., 2., 3., ...)\n",
    "            numbered_sections = re.split(r'(?=\\d+\\.\\s)', content_text)\n",
    "\n",
    "            part_index = 0  # Để đếm các phần\n",
    "            current_content = \"\"\n",
    "            for section in numbered_sections:\n",
    "                if count_tokens_simple(current_content + section) <= max_tokens:\n",
    "                    current_content += section\n",
    "                else:\n",
    "                    # Lưu phần nội dung hiện tại\n",
    "                    data.append({\n",
    "                        \"Chapter\": current_chapter,\n",
    "                        \"Chapter_Keywords\": process_value_to_keywords(current_chapter),\n",
    "                        \"Section\": current_section if current_section else None,\n",
    "                        \"Section_Keywords\": process_value_to_keywords(current_section),\n",
    "                        \"Mini-Section\": current_mini_section if current_mini_section else None,\n",
    "                        \"Mini-Section_Keywords\": process_value_to_keywords(current_mini_section),\n",
    "                        \"Article\": article,\n",
    "                        \"Article_Keywords\": process_value_to_keywords(article),\n",
    "                        \"Content\": current_content.strip(),\n",
    "                        \"Content_Keywords\": process_value_to_keywords(current_content),\n",
    "                        \"combine_Article_Content\": combine_article_content,\n",
    "                        \"key_words\": combined_keywords\n",
    "                    })\n",
    "                    part_index += 1\n",
    "                    current_content = section\n",
    "            \n",
    "            # Lưu phần nội dung còn lại nếu có\n",
    "            if current_content:\n",
    "                data.append({\n",
    "                    \"Chapter\": current_chapter,\n",
    "                    \"Chapter_Keywords\": process_value_to_keywords(current_chapter),\n",
    "                    \"Section\": current_section if current_section else None,\n",
    "                    \"Section_Keywords\": process_value_to_keywords(current_section),\n",
    "                    \"Mini-Section\": current_mini_section if current_mini_section else None,\n",
    "                    \"Mini-Section_Keywords\": process_value_to_keywords(current_mini_section),\n",
    "                    \"Article\": article,\n",
    "                    \"Article_Keywords\": process_value_to_keywords(article),\n",
    "                    \"Content\": current_content.strip(),\n",
    "                    \"Content_Keywords\": process_value_to_keywords(current_content),\n",
    "                    \"combine_Article_Content\": combine_article_content,\n",
    "                    \"key_words\": combined_keywords\n",
    "                })\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6. Hàm chính xử lý tất cả các file trong thư mục"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_folder(folder_path, output_json_path, max_tokens):\n",
    "    all_data = []\n",
    "    \n",
    "    for file_name in os.listdir(folder_path):\n",
    "        if file_name.endswith(\".docx\"):\n",
    "            file_metadata = process_file_name(file_name)\n",
    "            if file_metadata is None:\n",
    "                continue\n",
    "            \n",
    "            file_path = os.path.join(folder_path, file_name)\n",
    "            docx_data = process_docx(file_path, file_metadata, max_tokens=max_tokens)\n",
    "            \n",
    "            for entry in docx_data:\n",
    "                combined_entry = {**file_metadata, **entry}\n",
    "                all_data.append(combined_entry)\n",
    "    \n",
    "    with open(output_json_path, 'w', encoding='utf-8') as json_file:\n",
    "        json.dump(all_data, json_file, ensure_ascii=False, indent=4)\n",
    "    \n",
    "    print(f\"Dữ liệu đã được lưu vào file {output_json_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6. Thực thi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Đường dẫn tới thư mục và file đầu ra\n",
    "folder_path = r'data\\trich_dan_luat\\docx\\Luat'\n",
    "json_file_path = r'data\\trich_dan_luat\\json\\test_Article_Combined_Output_More_Keywords.json'\n",
    "max_tokens = 2048  # Giới hạn số token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dữ liệu đã được lưu vào file data\\trich_dan_luat\\json\\test_Article_Combined_Output_More_Keywords.json\n"
     ]
    }
   ],
   "source": [
    "# Chạy chương trình chính\n",
    "process_folder(folder_path, json_file_path, max_tokens)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
